{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9eaa10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import os, sys, re, pickle, glob\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b32a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dataset_path='/Users/esaltuk/Desktop/ELEC491/archive' \n",
    "metadata=pd.read_csv('/Users/esaltuk/Desktop/ELEC491/archive/MLEndHWD_Audio_Attributes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f3fdea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Public filename</th>\n",
       "      <th>Interpreter</th>\n",
       "      <th>Song</th>\n",
       "      <th>Interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.wav</td>\n",
       "      <td>216</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.wav</td>\n",
       "      <td>100</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002.wav</td>\n",
       "      <td>177</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003.wav</td>\n",
       "      <td>159</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004.wav</td>\n",
       "      <td>160</td>\n",
       "      <td>Potter</td>\n",
       "      <td>Whistle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>6606.wav</td>\n",
       "      <td>204</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>Hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6607</th>\n",
       "      <td>6607.wav</td>\n",
       "      <td>94</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>Hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6608</th>\n",
       "      <td>6608.wav</td>\n",
       "      <td>164</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>Hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>6609.wav</td>\n",
       "      <td>125</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>Hum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>6610.wav</td>\n",
       "      <td>87</td>\n",
       "      <td>Frozen</td>\n",
       "      <td>Whistle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6611 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Public filename  Interpreter    Song Interpretation\n",
       "0           0000.wav          216  Potter            Hum\n",
       "1           0001.wav          100  Potter            Hum\n",
       "2           0002.wav          177  Potter            Hum\n",
       "3           0003.wav          159  Potter            Hum\n",
       "4           0004.wav          160  Potter        Whistle\n",
       "...              ...          ...     ...            ...\n",
       "6606        6606.wav          204  Frozen            Hum\n",
       "6607        6607.wav           94  Frozen            Hum\n",
       "6608        6608.wav          164  Frozen            Hum\n",
       "6609        6609.wav          125  Frozen            Hum\n",
       "6610        6610.wav           87  Frozen        Whistle\n",
       "\n",
       "[6611 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb65eb1",
   "metadata": {},
   "source": [
    "def features_extractor(file):\n",
    "    \n",
    "    features=[]\n",
    "    \n",
    "    # if None, fs would be 22050\n",
    "    audio_data, sample_rate = librosa.load(file,mono=True,sr=22050)\n",
    "      \n",
    "\n",
    "    stft = np.abs(librosa.stft(audio_data))\n",
    "    \n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    features.extend(mfcc) # 40 = 40\n",
    "\n",
    "    \n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    features.extend(chroma) # 12 = 52\n",
    "    \n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=audio_data, sr=sample_rate).T,axis=0)\n",
    "    features.extend(mel) # 128 = 180\n",
    "    \n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    features.extend(contrast) # 7 = 187\n",
    "\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7bcf4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    features=[]    \n",
    "    audio_data, sample_rate = librosa.load(file,mono=True,sr=2*22050)\n",
    "    \n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    features.extend(mfcc) # 40 = 40\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "11329377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6611it [03:03, 36.09it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted_features=[]\n",
    "\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),\"MLEndHWD_\"+str(row[\"Song\"])+\"_Audio_Files\"+'/',str(row[\"Public filename\"]))\n",
    "    final_class_labels=row[\"Song\"]\n",
    "    Interpret = row[\"Interpretation\"]\n",
    "    if os.path.exists(file_name) == True:\n",
    "      data=features_extractor(file_name)\n",
    "      extracted_features.append([data,Interpret,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1fd686cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','Interp','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "50846ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Interp</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-371.79715, 127.446526, 2.6394265, 3.1592183,...</td>\n",
       "      <td>Hum</td>\n",
       "      <td>Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-505.87384, 130.31326, 22.047081, 20.901613, ...</td>\n",
       "      <td>Hum</td>\n",
       "      <td>Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-541.1099, 134.42548, 16.201548, 21.419962, 2...</td>\n",
       "      <td>Hum</td>\n",
       "      <td>Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-470.17938, 146.83046, 3.9286509, 8.309087, -...</td>\n",
       "      <td>Hum</td>\n",
       "      <td>Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-388.46826, 84.75418, 17.812887, -8.884424, 4...</td>\n",
       "      <td>Whistle</td>\n",
       "      <td>Potter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>[-476.7946, 124.91712, 4.0885925, 38.76391, 26...</td>\n",
       "      <td>Hum</td>\n",
       "      <td>Frozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6607</th>\n",
       "      <td>[-489.08978, 121.73104, 46.9286, 34.83716, 30....</td>\n",
       "      <td>Hum</td>\n",
       "      <td>Frozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6608</th>\n",
       "      <td>[-402.44797, 130.2624, 16.161236, 15.045093, 4...</td>\n",
       "      <td>Hum</td>\n",
       "      <td>Frozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>[-476.2789, 157.25711, 44.029285, 17.612562, -...</td>\n",
       "      <td>Hum</td>\n",
       "      <td>Frozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>[-477.03018, 108.591934, -27.411476, -42.99463...</td>\n",
       "      <td>Whistle</td>\n",
       "      <td>Frozen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6611 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                feature   Interp   class\n",
       "0     [-371.79715, 127.446526, 2.6394265, 3.1592183,...      Hum  Potter\n",
       "1     [-505.87384, 130.31326, 22.047081, 20.901613, ...      Hum  Potter\n",
       "2     [-541.1099, 134.42548, 16.201548, 21.419962, 2...      Hum  Potter\n",
       "3     [-470.17938, 146.83046, 3.9286509, 8.309087, -...      Hum  Potter\n",
       "4     [-388.46826, 84.75418, 17.812887, -8.884424, 4...  Whistle  Potter\n",
       "...                                                 ...      ...     ...\n",
       "6606  [-476.7946, 124.91712, 4.0885925, 38.76391, 26...      Hum  Frozen\n",
       "6607  [-489.08978, 121.73104, 46.9286, 34.83716, 30....      Hum  Frozen\n",
       "6608  [-402.44797, 130.2624, 16.161236, 15.045093, 4...      Hum  Frozen\n",
       "6609  [-476.2789, 157.25711, 44.029285, 17.612562, -...      Hum  Frozen\n",
       "6610  [-477.03018, 108.591934, -27.411476, -42.99463...  Whistle  Frozen\n",
       "\n",
       "[6611 rows x 3 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b6ecc608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "int_lbls=le.fit_transform(np.array(extracted_features_df.loc[:,\"Interp\"]))\n",
    "class_lbls=le.fit_transform(np.array(extracted_features_df.loc[:,\"class\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca79533",
   "metadata": {},
   "source": [
    "Determine whether the input is Humming or Whistle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "04710d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(pd.Series.tolist(extracted_features_df.feature)) # all the features\n",
    "\n",
    "y=int_lbls # hum or whistle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "72ee013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "fcc7498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_rem,y_rem,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4e618f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: (4627, 40) (4627,)\n",
      "Size of validation set: (1785, 40) (1785,)\n",
      "Size of testing set: (199, 40) (199,)\n"
     ]
    }
   ],
   "source": [
    "print('Size of training set:', X_train.shape, y_train.shape)\n",
    "print('Size of validation set:', X_val.shape, y_val.shape)\n",
    "print('Size of testing set:', X_test.shape, y_test.shape)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9a21483c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 0.9814134428355306\n",
      "Validation  Accuracy 0.9725490196078431\n"
     ]
    }
   ],
   "source": [
    "model  = svm.SVC(C=1)\n",
    "model.fit(np.array(X_train),y_train)\n",
    "\n",
    "yt_p = model.predict(X_train)\n",
    "yv_p = model.predict(X_val)\n",
    "\n",
    "print('Training Accuracy', np.mean(yt_p==y_train))\n",
    "print('Validation  Accuracy', np.mean(yv_p==y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "a1ac9351",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "extracted_features_df[\"Interp\"]=int_lbls\n",
    "extracted_features_df[\"class\"]=class_lbls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de7a9c4",
   "metadata": {},
   "source": [
    "Splitting the Hums and Whistles for later use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "675411fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hums=pd.DataFrame(extracted_features_df[extracted_features_df[\"Interp\"]==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "3c69527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "whistles=pd.DataFrame(extracted_features_df[extracted_features_df[\"Interp\"]==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e33b5",
   "metadata": {},
   "source": [
    "Training SVM Model for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "8307d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(pd.Series.tolist(extracted_features_df.feature)) # all the features\n",
    "\n",
    "y=class_lbls # classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "facaee7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7, 3, 5, 1, 2, 6, 0])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "55d480ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "7d37eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_rem,y_rem,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "6db6fb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: (4627, 40) (4627,)\n",
      "Size of validation set: (1785, 40) (1785,)\n",
      "Size of testing set: (199, 40) (199,)\n"
     ]
    }
   ],
   "source": [
    "print('Size of training set:', X_train.shape, y_train.shape)\n",
    "print('Size of validation set:', X_val.shape, y_val.shape)\n",
    "print('Size of testing set:', X_test.shape, y_test.shape)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "13a94436",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 1.0\n",
      "Validation  Accuracy 0.33501400560224087\n",
      "The support vectors are (4627, 40)\n",
      "Training confusion matrix:\n",
      " [[570   0   0   0   0   0   0   0]\n",
      " [  0 580   0   0   0   0   0   0]\n",
      " [  0   0 575   0   0   0   0   0]\n",
      " [  0   0   0 591   0   0   0   0]\n",
      " [  0   0   0   0 586   0   0   0]\n",
      " [  0   0   0   0   0 577   0   0]\n",
      " [  0   0   0   0   0   0 571   0]\n",
      " [  0   0   0   0   0   0   0 577]]\n",
      "\n",
      "Validation confusion matrix:\n",
      " [[ 41   2   4   4 156   1   7   3]\n",
      " [  3  58   9   4 136   2   3   5]\n",
      " [  2  14  65   6 139   1  10   4]\n",
      " [  1   3   3  78 126   3   1   9]\n",
      " [  1   0   0  11 207   2   1   7]\n",
      " [  2   1   1  11 153  50   2   7]\n",
      " [  4   6  13   3 125   1  51   3]\n",
      " [  0   3   1  11 152   2   3  48]]\n",
      "\n",
      "Normalised training confusion matrix:\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      "Normalised validation confusion matrix:\n",
      " [[0.18807339 0.00917431 0.01834862 0.01834862 0.71559633 0.00458716\n",
      "  0.03211009 0.01376147]\n",
      " [0.01363636 0.26363636 0.04090909 0.01818182 0.61818182 0.00909091\n",
      "  0.01363636 0.02272727]\n",
      " [0.00829876 0.05809129 0.26970954 0.02489627 0.57676349 0.00414938\n",
      "  0.04149378 0.01659751]\n",
      " [0.00446429 0.01339286 0.01339286 0.34821429 0.5625     0.01339286\n",
      "  0.00446429 0.04017857]\n",
      " [0.00436681 0.         0.         0.04803493 0.90393013 0.00873362\n",
      "  0.00436681 0.03056769]\n",
      " [0.00881057 0.00440529 0.00440529 0.04845815 0.67400881 0.22026432\n",
      "  0.00881057 0.030837  ]\n",
      " [0.01941748 0.02912621 0.0631068  0.01456311 0.60679612 0.00485437\n",
      "  0.24757282 0.01456311]\n",
      " [0.         0.01363636 0.00454545 0.05       0.69090909 0.00909091\n",
      "  0.01363636 0.21818182]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model  = svm.SVC(C=100, gamma=0.01, probability=True)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "yt_p = model.predict(X_train)\n",
    "yv_p = model.predict(X_val)\n",
    "\n",
    "print('Training Accuracy', np.mean(yt_p==y_train))\n",
    "print('Validation  Accuracy', np.mean(yv_p==y_val))\n",
    "print('The support vectors are', model.support_vectors_.shape)\n",
    "\n",
    "tcm = confusion_matrix(y_true=y_train, y_pred=yt_p)\n",
    "tcm_n = tcm.astype('float') / tcm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "vcm = confusion_matrix(y_true=y_val, y_pred=yv_p)\n",
    "vcm_n = vcm.astype('float') / vcm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print('Training confusion matrix:\\n {}\\n'.format(tcm))\n",
    "print('Validation confusion matrix:\\n {}\\n'.format(vcm))\n",
    "\n",
    "print('Normalised training confusion matrix:\\n {}\\n'.format(tcm_n))\n",
    "print('Normalised validation confusion matrix:\\n {}\\n'.format(vcm_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "094212cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1,1, 10, 100], \n",
    "    'gamma': [1,0.1,0.01,0.001],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "bc0a044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hums=hums[\"feature\"] # all the features\n",
    "y_hums=hums['class'] # hum or whistle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "78850325",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hums, X_rem, y_train_hums, y_rem = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "812c9034",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_hums, X_test_hums, y_val_hums, y_test_hums = train_test_split(X_rem,y_rem,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9271c67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: (4627, 40) (4627,)\n",
      "Size of validation set: (1785, 40) (1785,)\n",
      "Size of testing set: (199, 40) (199,)\n"
     ]
    }
   ],
   "source": [
    "print('Size of training set:', X_train_hums.shape, y_train_hums.shape)\n",
    "print('Size of validation set:', X_val_hums.shape, y_val_hums.shape)\n",
    "print('Size of testing set:', X_test_hums.shape, y_test_hums.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3fccb8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy of Humms 0.9997838772422736\n",
      "Validation  Accuracy Humms 0.11988795518207283\n",
      "The support vectors are (4627, 40)\n"
     ]
    }
   ],
   "source": [
    "model  = svm.SVC(C=10, gamma=0.1)\n",
    "model.fit(X_train_hums,y_train_hums)\n",
    "\n",
    "yt_p = model.predict(X_train_hums)\n",
    "yv_p = model.predict(X_val_hums)\n",
    "\n",
    "print('Training Accuracy of Humms', np.mean(yt_p==y_train_hums))\n",
    "print('Validation  Accuracy Humms', np.mean(yv_p==y_val_hums))\n",
    "print('The support vectors are', model.support_vectors_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "12be21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testyourdata(filename):\n",
    "    datatest=features_extractor(filename)\n",
    "    datatest=np.reshape(datatest,(1,-1))\n",
    "    test_result=model.predict(datatest)\n",
    "    probabilities = model.predict_proba(datatest)\n",
    "    print(np.sort(probabilities))\n",
    "    print(list(le.inverse_transform(np.argpartition(probabilities, -3)[:,-3:][0])))\n",
    "    return le.inverse_transform(np.reshape(test_result,(-1,1)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "332591db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data metrics are:\n",
      "Accuracy Score: 1.0\n",
      "The validation data metrics are:\n",
      "Accuracy Score: 0.40672268907563025\n",
      "\n",
      "\n",
      "The support vectors are (4627, 40) \n",
      "\n",
      "Training confusion matrix:\n",
      " [[570   0   0   0   0   0   0   0]\n",
      " [  0 580   0   0   0   0   0   0]\n",
      " [  0   0 575   0   0   0   0   0]\n",
      " [  0   0   0 591   0   0   0   0]\n",
      " [  0   0   0   0 586   0   0   0]\n",
      " [  0   0   0   0   0 577   0   0]\n",
      " [  0   0   0   0   0   0 571   0]\n",
      " [  0   0   0   0   0   0   0 577]]\n",
      "\n",
      "Validation confusion matrix:\n",
      " [[105  15  20  13  20   7  21  17]\n",
      " [ 10  82  46  17   9  16  26  14]\n",
      " [ 20  34 108  18  16  14  23   8]\n",
      " [ 16  15  22  97  32  11  10  21]\n",
      " [ 15  12  16  34  96  22  19  15]\n",
      " [ 11   8  10  34  26 103  21  14]\n",
      " [ 18  13  48  16  19   9  72  11]\n",
      " [ 20  17  25  31  26  22  16  63]]\n",
      "\n",
      "Normalised training confusion matrix:\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      "Normalised validation confusion matrix:\n",
      " [[0.48165138 0.06880734 0.09174312 0.05963303 0.09174312 0.03211009\n",
      "  0.09633028 0.07798165]\n",
      " [0.04545455 0.37272727 0.20909091 0.07727273 0.04090909 0.07272727\n",
      "  0.11818182 0.06363636]\n",
      " [0.08298755 0.14107884 0.44813278 0.0746888  0.06639004 0.05809129\n",
      "  0.09543568 0.03319502]\n",
      " [0.07142857 0.06696429 0.09821429 0.43303571 0.14285714 0.04910714\n",
      "  0.04464286 0.09375   ]\n",
      " [0.06550218 0.05240175 0.069869   0.14847162 0.41921397 0.09606987\n",
      "  0.08296943 0.06550218]\n",
      " [0.04845815 0.03524229 0.04405286 0.14977974 0.11453744 0.45374449\n",
      "  0.09251101 0.06167401]\n",
      " [0.08737864 0.0631068  0.23300971 0.0776699  0.09223301 0.04368932\n",
      "  0.34951456 0.05339806]\n",
      " [0.09090909 0.07727273 0.11363636 0.14090909 0.11818182 0.1\n",
      "  0.07272727 0.28636364]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "xgbc = XGBClassifier()\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
    "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
    "       n_estimators=100, n_jobs=1, nthread=None,\n",
    "       objective='multi:softmax', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
    "       subsample=1, verbosity=1 , num_class=8)\n",
    "\n",
    "xgbc.fit(X_train, y_train)\n",
    "\n",
    "print('The training data metrics are:')\n",
    "print('Accuracy Score:', accuracy_score(y_true=y_train, y_pred=xgbc.predict(X_train)))\n",
    "\n",
    "print('The validation data metrics are:')\n",
    "print('Accuracy Score:', accuracy_score(y_true=y_val, y_pred=xgbc.predict(X_val)))\n",
    "\n",
    "print('\\n')\n",
    "print('The support vectors are', model.support_vectors_.shape, ('\\n'))\n",
    "\n",
    "tcm = confusion_matrix(y_true=y_train, y_pred=xgbc.predict(X_train))\n",
    "tcm_n = tcm.astype('float') / tcm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "vcm = confusion_matrix(y_true=y_val, y_pred=xgbc.predict(X_val))\n",
    "vcm_n = vcm.astype('float') / vcm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print('Training confusion matrix:\\n {}\\n'.format(tcm))\n",
    "print('Validation confusion matrix:\\n {}\\n'.format(vcm))\n",
    "\n",
    "print('Normalised training confusion matrix:\\n {}\\n'.format(tcm_n))\n",
    "print('Normalised validation confusion matrix:\\n {}\\n'.format(vcm_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d8de5692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input,Dense, LSTM, Dropout,Activation,Flatten, Conv2D ,Conv1D, MaxPooling1D,MaxPooling2D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics, model_selection\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "c81dd8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Training / Fitting / Optimizing Model #####\n",
    "test_size = 0.3\n",
    "epochs    = 100\n",
    "batch_size= 10\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b79eca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= ['Frozen', 'Harry', 'Panther', 'StarWars', 'Rain','Hakuna', 'Mamma']\n",
    "n_classes=len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "22c845b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4627, 40)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2d010c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(40,)))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "172ba9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Define the model\n",
    "model.add(Input(shape=(40,)))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "dcf5d00b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_23 (Dense)            (None, 256)               10496     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 7)                 1799      \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,087\n",
      "Trainable params: 78,087\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "eb0aa795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 13.6626 - accuracy: 0.1232 - val_loss: 9.7749 - val_accuracy: 0.1462\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 15.9777 - accuracy: 0.1366 - val_loss: 31.0667 - val_accuracy: 0.1232\n",
      "Epoch 3/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 117.3036 - accuracy: 0.1210 - val_loss: 398.6978 - val_accuracy: 0.1221\n",
      "Epoch 4/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 516.7823 - accuracy: 0.1277 - val_loss: 1719.6665 - val_accuracy: 0.1154\n",
      "Epoch 5/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 1147.9557 - accuracy: 0.1178 - val_loss: 2351.7522 - val_accuracy: 0.1160\n",
      "Epoch 6/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 2382.0310 - accuracy: 0.1264 - val_loss: 6554.8594 - val_accuracy: 0.1272\n",
      "Epoch 7/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 3440.3501 - accuracy: 0.1202 - val_loss: 9130.8955 - val_accuracy: 0.1272\n",
      "Epoch 8/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 5304.8120 - accuracy: 0.1254 - val_loss: 20441.8418 - val_accuracy: 0.1272\n",
      "Epoch 9/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 7588.6147 - accuracy: 0.1206 - val_loss: 25309.7598 - val_accuracy: 0.1272\n",
      "Epoch 10/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 9487.0977 - accuracy: 0.1221 - val_loss: 34647.4805 - val_accuracy: 0.1272\n",
      "Epoch 11/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 12544.3223 - accuracy: 0.1251 - val_loss: 43086.9258 - val_accuracy: 0.1272\n",
      "Epoch 12/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 14601.7012 - accuracy: 0.1284 - val_loss: 48395.5977 - val_accuracy: 0.1154\n",
      "Epoch 13/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 18259.6055 - accuracy: 0.1288 - val_loss: 56784.3711 - val_accuracy: 0.1154\n",
      "Epoch 14/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 20605.2988 - accuracy: 0.1234 - val_loss: 57783.9883 - val_accuracy: 0.1154\n",
      "Epoch 15/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 23172.8066 - accuracy: 0.1331 - val_loss: 112529.6953 - val_accuracy: 0.1272\n",
      "Epoch 16/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 28947.9941 - accuracy: 0.1310 - val_loss: 124282.9062 - val_accuracy: 0.1272\n",
      "Epoch 17/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 36622.7617 - accuracy: 0.1243 - val_loss: 109971.6328 - val_accuracy: 0.1154\n",
      "Epoch 18/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 36290.0938 - accuracy: 0.1236 - val_loss: 148234.4531 - val_accuracy: 0.1154\n",
      "Epoch 19/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 39455.8203 - accuracy: 0.1312 - val_loss: 151933.1250 - val_accuracy: 0.1272\n",
      "Epoch 20/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 47461.3555 - accuracy: 0.1273 - val_loss: 155380.8125 - val_accuracy: 0.1154\n",
      "Epoch 21/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 52977.1836 - accuracy: 0.1189 - val_loss: 209932.4375 - val_accuracy: 0.1272\n",
      "Epoch 22/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 54715.4922 - accuracy: 0.1336 - val_loss: 240600.9688 - val_accuracy: 0.1154\n",
      "Epoch 23/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 66155.1875 - accuracy: 0.1230 - val_loss: 274073.4688 - val_accuracy: 0.1272\n",
      "Epoch 24/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 62719.6250 - accuracy: 0.1225 - val_loss: 274815.4375 - val_accuracy: 0.1272\n",
      "Epoch 25/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 71187.0469 - accuracy: 0.1312 - val_loss: 251199.5312 - val_accuracy: 0.1154\n",
      "Epoch 26/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 79332.7031 - accuracy: 0.1249 - val_loss: 356126.3125 - val_accuracy: 0.1154\n",
      "Epoch 27/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 78280.3672 - accuracy: 0.1221 - val_loss: 283982.4688 - val_accuracy: 0.1154\n",
      "Epoch 28/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 90686.3125 - accuracy: 0.1269 - val_loss: 369643.5000 - val_accuracy: 0.1272\n",
      "Epoch 29/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 96386.5703 - accuracy: 0.1247 - val_loss: 468212.3438 - val_accuracy: 0.1272\n",
      "Epoch 30/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 103863.4375 - accuracy: 0.1305 - val_loss: 617989.4375 - val_accuracy: 0.1272\n",
      "Epoch 31/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 112086.7031 - accuracy: 0.1234 - val_loss: 563093.7500 - val_accuracy: 0.1272\n",
      "Epoch 32/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 118255.3984 - accuracy: 0.1254 - val_loss: 363448.1562 - val_accuracy: 0.1272\n",
      "Epoch 33/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 117580.1328 - accuracy: 0.1241 - val_loss: 606630.0625 - val_accuracy: 0.1272\n",
      "Epoch 34/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 111957.6172 - accuracy: 0.1312 - val_loss: 589357.9375 - val_accuracy: 0.1272\n",
      "Epoch 35/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 119671.6328 - accuracy: 0.1249 - val_loss: 747864.3750 - val_accuracy: 0.1272\n",
      "Epoch 36/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 121840.2422 - accuracy: 0.1187 - val_loss: 692547.7500 - val_accuracy: 0.1272\n",
      "Epoch 37/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 137305.1562 - accuracy: 0.1234 - val_loss: 716305.1250 - val_accuracy: 0.1272\n",
      "Epoch 38/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 142586.3750 - accuracy: 0.1202 - val_loss: 789565.8125 - val_accuracy: 0.1272\n",
      "Epoch 39/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 158493.2344 - accuracy: 0.1249 - val_loss: 800990.8750 - val_accuracy: 0.1272\n",
      "Epoch 40/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 177325.7344 - accuracy: 0.1193 - val_loss: 837608.0625 - val_accuracy: 0.1272\n",
      "Epoch 41/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 184811.1406 - accuracy: 0.1305 - val_loss: 742562.8750 - val_accuracy: 0.1154\n",
      "Epoch 42/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 178251.0000 - accuracy: 0.1228 - val_loss: 816586.8750 - val_accuracy: 0.1272\n",
      "Epoch 43/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 173102.0000 - accuracy: 0.1232 - val_loss: 931365.0625 - val_accuracy: 0.1272\n",
      "Epoch 44/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 186367.9219 - accuracy: 0.1247 - val_loss: 1139668.7500 - val_accuracy: 0.1272\n",
      "Epoch 45/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 202019.3750 - accuracy: 0.1154 - val_loss: 1017223.1875 - val_accuracy: 0.1272\n",
      "Epoch 46/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 200258.7344 - accuracy: 0.1312 - val_loss: 1034124.3125 - val_accuracy: 0.1272\n",
      "Epoch 47/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 212970.9531 - accuracy: 0.1275 - val_loss: 1228834.0000 - val_accuracy: 0.1272\n",
      "Epoch 48/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 220234.1094 - accuracy: 0.1206 - val_loss: 1131248.5000 - val_accuracy: 0.1154\n",
      "Epoch 49/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 231335.2656 - accuracy: 0.1329 - val_loss: 1094269.5000 - val_accuracy: 0.1272\n",
      "Epoch 50/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 217079.3750 - accuracy: 0.1310 - val_loss: 1197819.0000 - val_accuracy: 0.1272\n",
      "Epoch 51/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 228008.5469 - accuracy: 0.1249 - val_loss: 1130110.1250 - val_accuracy: 0.1154\n",
      "Epoch 52/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 231937.4062 - accuracy: 0.1286 - val_loss: 1422350.3750 - val_accuracy: 0.1272\n",
      "Epoch 53/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 267106.4375 - accuracy: 0.1256 - val_loss: 1288853.5000 - val_accuracy: 0.1272\n",
      "Epoch 54/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 260302.5938 - accuracy: 0.1225 - val_loss: 1584374.5000 - val_accuracy: 0.1272\n",
      "Epoch 55/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 279929.7812 - accuracy: 0.1204 - val_loss: 1397497.5000 - val_accuracy: 0.1154\n",
      "Epoch 56/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 283020.3125 - accuracy: 0.1215 - val_loss: 1308334.1250 - val_accuracy: 0.1272\n",
      "Epoch 57/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 290550.4375 - accuracy: 0.1197 - val_loss: 1477213.7500 - val_accuracy: 0.1272\n",
      "Epoch 58/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 273374.5312 - accuracy: 0.1295 - val_loss: 1770744.1250 - val_accuracy: 0.1272\n",
      "Epoch 59/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 308462.0625 - accuracy: 0.1279 - val_loss: 1708459.3750 - val_accuracy: 0.1154\n",
      "Epoch 60/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 307840.9688 - accuracy: 0.1206 - val_loss: 1752023.1250 - val_accuracy: 0.1272\n",
      "Epoch 61/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 311488.7188 - accuracy: 0.1264 - val_loss: 1641364.1250 - val_accuracy: 0.1154\n",
      "Epoch 62/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 362882.7812 - accuracy: 0.1290 - val_loss: 1852877.5000 - val_accuracy: 0.1272\n",
      "Epoch 63/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 338610.7812 - accuracy: 0.1176 - val_loss: 2018887.1250 - val_accuracy: 0.1272\n",
      "Epoch 64/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 395987.8438 - accuracy: 0.1333 - val_loss: 2019942.5000 - val_accuracy: 0.1272\n",
      "Epoch 65/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 326660.0312 - accuracy: 0.1327 - val_loss: 2154101.2500 - val_accuracy: 0.1154\n",
      "Epoch 66/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 357964.8438 - accuracy: 0.1314 - val_loss: 2035798.6250 - val_accuracy: 0.1272\n",
      "Epoch 67/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 376145.4688 - accuracy: 0.1197 - val_loss: 2177537.0000 - val_accuracy: 0.1272\n",
      "Epoch 68/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 384437.0000 - accuracy: 0.1202 - val_loss: 2306272.0000 - val_accuracy: 0.1272\n",
      "Epoch 69/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 378731.0000 - accuracy: 0.1204 - val_loss: 2103878.2500 - val_accuracy: 0.1272\n",
      "Epoch 70/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 407033.7500 - accuracy: 0.1254 - val_loss: 2390650.2500 - val_accuracy: 0.1272\n",
      "Epoch 71/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 376421.1562 - accuracy: 0.1292 - val_loss: 2566720.0000 - val_accuracy: 0.1272\n",
      "Epoch 72/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 413396.5625 - accuracy: 0.1260 - val_loss: 2778932.2500 - val_accuracy: 0.1272\n",
      "Epoch 73/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 422346.9062 - accuracy: 0.1161 - val_loss: 2504626.5000 - val_accuracy: 0.1272\n",
      "Epoch 74/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 432106.5938 - accuracy: 0.1353 - val_loss: 2664388.0000 - val_accuracy: 0.1154\n",
      "Epoch 75/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 537497.7500 - accuracy: 0.1210 - val_loss: 2894272.2500 - val_accuracy: 0.1154\n",
      "Epoch 76/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 527014.3125 - accuracy: 0.1221 - val_loss: 2978078.5000 - val_accuracy: 0.1272\n",
      "Epoch 77/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 491306.5938 - accuracy: 0.1262 - val_loss: 2453581.5000 - val_accuracy: 0.1272\n",
      "Epoch 78/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 480663.0000 - accuracy: 0.1217 - val_loss: 2396901.5000 - val_accuracy: 0.1154\n",
      "Epoch 79/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 488020.7500 - accuracy: 0.1321 - val_loss: 3326776.2500 - val_accuracy: 0.1272\n",
      "Epoch 80/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 508032.9688 - accuracy: 0.1176 - val_loss: 3091833.0000 - val_accuracy: 0.1272\n",
      "Epoch 81/100\n",
      "145/145 [==============================] - 1s 5ms/step - loss: 467635.4375 - accuracy: 0.1290 - val_loss: 3066732.5000 - val_accuracy: 0.1272\n",
      "Epoch 82/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 488240.9062 - accuracy: 0.1212 - val_loss: 2982462.0000 - val_accuracy: 0.1272\n",
      "Epoch 83/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 554513.6250 - accuracy: 0.1221 - val_loss: 3384404.2500 - val_accuracy: 0.1272\n",
      "Epoch 84/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 519232.7812 - accuracy: 0.1208 - val_loss: 3328643.7500 - val_accuracy: 0.1272\n",
      "Epoch 85/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 573251.8125 - accuracy: 0.1184 - val_loss: 3583774.5000 - val_accuracy: 0.1272\n",
      "Epoch 86/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 524642.8750 - accuracy: 0.1249 - val_loss: 3786831.5000 - val_accuracy: 0.1272\n",
      "Epoch 87/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 604673.8125 - accuracy: 0.1249 - val_loss: 3712709.2500 - val_accuracy: 0.1272\n",
      "Epoch 88/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 536164.7500 - accuracy: 0.1215 - val_loss: 3299683.7500 - val_accuracy: 0.1272\n",
      "Epoch 89/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 580308.1250 - accuracy: 0.1161 - val_loss: 3635883.5000 - val_accuracy: 0.1272\n",
      "Epoch 90/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 685009.5000 - accuracy: 0.1234 - val_loss: 4132549.7500 - val_accuracy: 0.1272\n",
      "Epoch 91/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 672765.0000 - accuracy: 0.1202 - val_loss: 4198851.0000 - val_accuracy: 0.1272\n",
      "Epoch 92/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 608837.3750 - accuracy: 0.1254 - val_loss: 3827143.0000 - val_accuracy: 0.1272\n",
      "Epoch 93/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 672364.8750 - accuracy: 0.1195 - val_loss: 4335488.0000 - val_accuracy: 0.1272\n",
      "Epoch 94/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 682241.0000 - accuracy: 0.1238 - val_loss: 4110451.2500 - val_accuracy: 0.1272\n",
      "Epoch 95/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 726785.6250 - accuracy: 0.1210 - val_loss: 4864841.0000 - val_accuracy: 0.1272\n",
      "Epoch 96/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 668264.8750 - accuracy: 0.1236 - val_loss: 4492481.0000 - val_accuracy: 0.1272\n",
      "Epoch 97/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 761627.5625 - accuracy: 0.1165 - val_loss: 4345751.0000 - val_accuracy: 0.1272\n",
      "Epoch 98/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 685281.2500 - accuracy: 0.1232 - val_loss: 3904440.2500 - val_accuracy: 0.1272\n",
      "Epoch 99/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 681460.7500 - accuracy: 0.1321 - val_loss: 4163654.7500 - val_accuracy: 0.1154\n",
      "Epoch 100/100\n",
      "145/145 [==============================] - 1s 6ms/step - loss: 715518.0000 - accuracy: 0.1221 - val_loss: 4290038.5000 - val_accuracy: 0.1272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7aaddff70>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=100,validation_data=(X_val, y_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b945d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8de3b11e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "145/145 [==============================] - 2s 10ms/step - loss: 587.5239 - accuracy: 0.1225 - val_loss: 4632.7500 - val_accuracy: 0.1339\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 44351.1172 - accuracy: 0.1241 - val_loss: 54240.2578 - val_accuracy: 0.1120\n",
      "Epoch 3/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 308890.5625 - accuracy: 0.1230 - val_loss: 330113.1875 - val_accuracy: 0.1199\n",
      "Epoch 4/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 735493.7500 - accuracy: 0.1303 - val_loss: 658403.0625 - val_accuracy: 0.1120\n",
      "Epoch 5/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1493999.8750 - accuracy: 0.1273 - val_loss: 1568499.2500 - val_accuracy: 0.1473\n",
      "Epoch 6/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 2498185.2500 - accuracy: 0.1197 - val_loss: 1670282.1250 - val_accuracy: 0.1199\n",
      "Epoch 7/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 3722653.7500 - accuracy: 0.1241 - val_loss: 2972080.7500 - val_accuracy: 0.1322\n",
      "Epoch 8/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 5747768.0000 - accuracy: 0.1299 - val_loss: 4059586.0000 - val_accuracy: 0.1473\n",
      "Epoch 9/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 5667641.0000 - accuracy: 0.1333 - val_loss: 5743393.0000 - val_accuracy: 0.1322\n",
      "Epoch 10/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 8262475.5000 - accuracy: 0.1275 - val_loss: 9567348.0000 - val_accuracy: 0.1322\n",
      "Epoch 11/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 11022448.0000 - accuracy: 0.1316 - val_loss: 4777820.0000 - val_accuracy: 0.1160\n",
      "Epoch 12/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 14470434.0000 - accuracy: 0.1301 - val_loss: 15271410.0000 - val_accuracy: 0.1322\n",
      "Epoch 13/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 17357270.0000 - accuracy: 0.1243 - val_loss: 13137323.0000 - val_accuracy: 0.1120\n",
      "Epoch 14/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 19705906.0000 - accuracy: 0.1193 - val_loss: 24337800.0000 - val_accuracy: 0.1473\n",
      "Epoch 15/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 23345834.0000 - accuracy: 0.1219 - val_loss: 24743264.0000 - val_accuracy: 0.1120\n",
      "Epoch 16/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 25961420.0000 - accuracy: 0.1230 - val_loss: 20399112.0000 - val_accuracy: 0.1160\n",
      "Epoch 17/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 30542546.0000 - accuracy: 0.1241 - val_loss: 9847900.0000 - val_accuracy: 0.1339\n",
      "Epoch 18/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 35760620.0000 - accuracy: 0.1266 - val_loss: 14282476.0000 - val_accuracy: 0.1120\n",
      "Epoch 19/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 41202048.0000 - accuracy: 0.1161 - val_loss: 38574492.0000 - val_accuracy: 0.1199\n",
      "Epoch 20/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 44261132.0000 - accuracy: 0.1273 - val_loss: 49779024.0000 - val_accuracy: 0.1160\n",
      "Epoch 21/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 53517640.0000 - accuracy: 0.1208 - val_loss: 73619440.0000 - val_accuracy: 0.1120\n",
      "Epoch 22/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 54015832.0000 - accuracy: 0.1212 - val_loss: 76898336.0000 - val_accuracy: 0.1120\n",
      "Epoch 23/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 61956904.0000 - accuracy: 0.1338 - val_loss: 51842864.0000 - val_accuracy: 0.1322\n",
      "Epoch 24/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 65396068.0000 - accuracy: 0.1383 - val_loss: 42051424.0000 - val_accuracy: 0.1473\n",
      "Epoch 25/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 77694712.0000 - accuracy: 0.1221 - val_loss: 60771064.0000 - val_accuracy: 0.1199\n",
      "Epoch 26/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 78495288.0000 - accuracy: 0.1329 - val_loss: 42270548.0000 - val_accuracy: 0.1120\n",
      "Epoch 27/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 94487872.0000 - accuracy: 0.1245 - val_loss: 76429544.0000 - val_accuracy: 0.1322\n",
      "Epoch 28/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 103231480.0000 - accuracy: 0.1230 - val_loss: 96092320.0000 - val_accuracy: 0.1120\n",
      "Epoch 29/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 109774584.0000 - accuracy: 0.1238 - val_loss: 73903096.0000 - val_accuracy: 0.1199\n",
      "Epoch 30/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 115051224.0000 - accuracy: 0.1262 - val_loss: 140030736.0000 - val_accuracy: 0.1199\n",
      "Epoch 31/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 139480432.0000 - accuracy: 0.1212 - val_loss: 72723448.0000 - val_accuracy: 0.1473\n",
      "Epoch 32/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 131559976.0000 - accuracy: 0.1290 - val_loss: 72992936.0000 - val_accuracy: 0.1199\n",
      "Epoch 33/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 141016368.0000 - accuracy: 0.1232 - val_loss: 63781400.0000 - val_accuracy: 0.1199\n",
      "Epoch 34/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 170591712.0000 - accuracy: 0.1243 - val_loss: 218634624.0000 - val_accuracy: 0.1473\n",
      "Epoch 35/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 170319264.0000 - accuracy: 0.1193 - val_loss: 268668640.0000 - val_accuracy: 0.1322\n",
      "Epoch 36/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 193296112.0000 - accuracy: 0.1212 - val_loss: 199374400.0000 - val_accuracy: 0.1339\n",
      "Epoch 37/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 197393056.0000 - accuracy: 0.1288 - val_loss: 177106160.0000 - val_accuracy: 0.1120\n",
      "Epoch 38/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 204289456.0000 - accuracy: 0.1223 - val_loss: 185685024.0000 - val_accuracy: 0.1160\n",
      "Epoch 39/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 217695952.0000 - accuracy: 0.1312 - val_loss: 264142368.0000 - val_accuracy: 0.1339\n",
      "Epoch 40/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 269416064.0000 - accuracy: 0.1199 - val_loss: 119985720.0000 - val_accuracy: 0.1339\n",
      "Epoch 41/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 259928928.0000 - accuracy: 0.1191 - val_loss: 146981520.0000 - val_accuracy: 0.1322\n",
      "Epoch 42/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 271366336.0000 - accuracy: 0.1191 - val_loss: 196151504.0000 - val_accuracy: 0.1120\n",
      "Epoch 43/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 297273856.0000 - accuracy: 0.1288 - val_loss: 419832800.0000 - val_accuracy: 0.1120\n",
      "Epoch 44/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 328197856.0000 - accuracy: 0.1327 - val_loss: 161787136.0000 - val_accuracy: 0.1322\n",
      "Epoch 45/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 364952352.0000 - accuracy: 0.1143 - val_loss: 187985120.0000 - val_accuracy: 0.1473\n",
      "Epoch 46/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 370158784.0000 - accuracy: 0.1158 - val_loss: 122568408.0000 - val_accuracy: 0.1199\n",
      "Epoch 47/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 366499744.0000 - accuracy: 0.1301 - val_loss: 340748672.0000 - val_accuracy: 0.1339\n",
      "Epoch 48/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 399805536.0000 - accuracy: 0.1305 - val_loss: 304838784.0000 - val_accuracy: 0.1199\n",
      "Epoch 49/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 464783712.0000 - accuracy: 0.1271 - val_loss: 402458912.0000 - val_accuracy: 0.1120\n",
      "Epoch 50/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 442908928.0000 - accuracy: 0.1303 - val_loss: 569147456.0000 - val_accuracy: 0.1160\n",
      "Epoch 51/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 441439776.0000 - accuracy: 0.1262 - val_loss: 421541824.0000 - val_accuracy: 0.1322\n",
      "Epoch 52/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 476313280.0000 - accuracy: 0.1228 - val_loss: 273092768.0000 - val_accuracy: 0.1120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 593773312.0000 - accuracy: 0.1145 - val_loss: 468877376.0000 - val_accuracy: 0.1199\n",
      "Epoch 54/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 502675360.0000 - accuracy: 0.1318 - val_loss: 300269504.0000 - val_accuracy: 0.1199\n",
      "Epoch 55/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 584505984.0000 - accuracy: 0.1254 - val_loss: 720322944.0000 - val_accuracy: 0.1322\n",
      "Epoch 56/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 659166144.0000 - accuracy: 0.1111 - val_loss: 295465952.0000 - val_accuracy: 0.1473\n",
      "Epoch 57/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 566854400.0000 - accuracy: 0.1342 - val_loss: 479031040.0000 - val_accuracy: 0.1120\n",
      "Epoch 58/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 693298560.0000 - accuracy: 0.1284 - val_loss: 584259648.0000 - val_accuracy: 0.1322\n",
      "Epoch 59/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 706183552.0000 - accuracy: 0.1301 - val_loss: 569571072.0000 - val_accuracy: 0.1120\n",
      "Epoch 60/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 750291776.0000 - accuracy: 0.1161 - val_loss: 704142144.0000 - val_accuracy: 0.1199\n",
      "Epoch 61/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 780938944.0000 - accuracy: 0.1217 - val_loss: 536601216.0000 - val_accuracy: 0.1339\n",
      "Epoch 62/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 802776256.0000 - accuracy: 0.1241 - val_loss: 532807328.0000 - val_accuracy: 0.1160\n",
      "Epoch 63/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 814834432.0000 - accuracy: 0.1236 - val_loss: 964705472.0000 - val_accuracy: 0.1120\n",
      "Epoch 64/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 865933248.0000 - accuracy: 0.1221 - val_loss: 1459680384.0000 - val_accuracy: 0.1160\n",
      "Epoch 65/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 852139648.0000 - accuracy: 0.1269 - val_loss: 756009536.0000 - val_accuracy: 0.1120\n",
      "Epoch 66/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1030119872.0000 - accuracy: 0.1277 - val_loss: 855615040.0000 - val_accuracy: 0.1120\n",
      "Epoch 67/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 956580096.0000 - accuracy: 0.1305 - val_loss: 671287616.0000 - val_accuracy: 0.1473\n",
      "Epoch 68/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 969307136.0000 - accuracy: 0.1247 - val_loss: 921926400.0000 - val_accuracy: 0.1120\n",
      "Epoch 69/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1185775872.0000 - accuracy: 0.1323 - val_loss: 1161719168.0000 - val_accuracy: 0.1322\n",
      "Epoch 70/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1074203520.0000 - accuracy: 0.1269 - val_loss: 506577664.0000 - val_accuracy: 0.1339\n",
      "Epoch 71/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1128621056.0000 - accuracy: 0.1202 - val_loss: 947600384.0000 - val_accuracy: 0.1160\n",
      "Epoch 72/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1423038848.0000 - accuracy: 0.1184 - val_loss: 647608768.0000 - val_accuracy: 0.1120\n",
      "Epoch 73/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1266661888.0000 - accuracy: 0.1161 - val_loss: 488428480.0000 - val_accuracy: 0.1339\n",
      "Epoch 74/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 1138656000.0000 - accuracy: 0.1292 - val_loss: 779665920.0000 - val_accuracy: 0.1120\n",
      "Epoch 75/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1312946432.0000 - accuracy: 0.1290 - val_loss: 1183121920.0000 - val_accuracy: 0.1120\n",
      "Epoch 76/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1364106496.0000 - accuracy: 0.1303 - val_loss: 878102976.0000 - val_accuracy: 0.1322\n",
      "Epoch 77/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1616174976.0000 - accuracy: 0.1223 - val_loss: 1251045504.0000 - val_accuracy: 0.1322\n",
      "Epoch 78/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1593342592.0000 - accuracy: 0.1228 - val_loss: 1412760576.0000 - val_accuracy: 0.1199\n",
      "Epoch 79/100\n",
      "145/145 [==============================] - 1s 8ms/step - loss: 1573224832.0000 - accuracy: 0.1249 - val_loss: 1278619392.0000 - val_accuracy: 0.1120\n",
      "Epoch 80/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1650061440.0000 - accuracy: 0.1230 - val_loss: 1218841728.0000 - val_accuracy: 0.1339\n",
      "Epoch 81/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1708941568.0000 - accuracy: 0.1184 - val_loss: 1234992000.0000 - val_accuracy: 0.1120\n",
      "Epoch 82/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1757914240.0000 - accuracy: 0.1308 - val_loss: 1804893952.0000 - val_accuracy: 0.1120\n",
      "Epoch 83/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1758072960.0000 - accuracy: 0.1323 - val_loss: 1553796736.0000 - val_accuracy: 0.1339\n",
      "Epoch 84/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1939405312.0000 - accuracy: 0.1210 - val_loss: 1057267456.0000 - val_accuracy: 0.1120\n",
      "Epoch 85/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1884895744.0000 - accuracy: 0.1273 - val_loss: 1579925888.0000 - val_accuracy: 0.1120\n",
      "Epoch 86/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 1992976512.0000 - accuracy: 0.1161 - val_loss: 1854418176.0000 - val_accuracy: 0.1322\n",
      "Epoch 87/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 2195791616.0000 - accuracy: 0.1256 - val_loss: 1160095744.0000 - val_accuracy: 0.1473\n",
      "Epoch 88/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 2090882816.0000 - accuracy: 0.1353 - val_loss: 3314655744.0000 - val_accuracy: 0.1160\n",
      "Epoch 89/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 2307388928.0000 - accuracy: 0.1191 - val_loss: 1018265472.0000 - val_accuracy: 0.1473\n",
      "Epoch 90/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 2429391104.0000 - accuracy: 0.1223 - val_loss: 1891783936.0000 - val_accuracy: 0.1339\n",
      "Epoch 91/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 2453715712.0000 - accuracy: 0.1258 - val_loss: 2682850304.0000 - val_accuracy: 0.1322\n",
      "Epoch 92/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 2571387392.0000 - accuracy: 0.1230 - val_loss: 1026299840.0000 - val_accuracy: 0.1120\n",
      "Epoch 93/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 2474381568.0000 - accuracy: 0.1191 - val_loss: 2877140992.0000 - val_accuracy: 0.1160\n",
      "Epoch 94/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 2512810496.0000 - accuracy: 0.1292 - val_loss: 1522160896.0000 - val_accuracy: 0.1160\n",
      "Epoch 95/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 2575425024.0000 - accuracy: 0.1273 - val_loss: 1652493056.0000 - val_accuracy: 0.1473\n",
      "Epoch 96/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 2915915776.0000 - accuracy: 0.1254 - val_loss: 917234112.0000 - val_accuracy: 0.1339\n",
      "Epoch 97/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 2721249792.0000 - accuracy: 0.1295 - val_loss: 1245513856.0000 - val_accuracy: 0.1473\n",
      "Epoch 98/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 2879746048.0000 - accuracy: 0.1256 - val_loss: 1724557440.0000 - val_accuracy: 0.1120\n",
      "Epoch 99/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 3259261696.0000 - accuracy: 0.1232 - val_loss: 1625566592.0000 - val_accuracy: 0.1199\n",
      "Epoch 100/100\n",
      "145/145 [==============================] - 1s 7ms/step - loss: 3391791872.0000 - accuracy: 0.1187 - val_loss: 2508401920.0000 - val_accuracy: 0.1160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x33e478b50>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(186, 1)))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# fit network\n",
    "model.fit(X_train, y_train, epochs=100,validation_data=(X_val,y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "82a720d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "145/145 [==============================] - 8s 45ms/step - loss: 2.0831 - accuracy: 0.1591 - val_loss: 2.0658 - val_accuracy: 0.1630\n",
      "Epoch 2/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0605 - accuracy: 0.1651 - val_loss: 2.0739 - val_accuracy: 0.1574\n",
      "Epoch 3/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 2.0545 - accuracy: 0.1764 - val_loss: 2.0683 - val_accuracy: 0.1462\n",
      "Epoch 4/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0516 - accuracy: 0.1787 - val_loss: 2.0624 - val_accuracy: 0.1585\n",
      "Epoch 5/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0437 - accuracy: 0.1848 - val_loss: 2.0512 - val_accuracy: 0.1681\n",
      "Epoch 6/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0408 - accuracy: 0.1800 - val_loss: 2.0560 - val_accuracy: 0.1636\n",
      "Epoch 7/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0382 - accuracy: 0.1839 - val_loss: 2.0454 - val_accuracy: 0.1675\n",
      "Epoch 8/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0309 - accuracy: 0.1869 - val_loss: 2.0408 - val_accuracy: 0.1754\n",
      "Epoch 9/100\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 2.0310 - accuracy: 0.1856 - val_loss: 2.0415 - val_accuracy: 0.1754\n",
      "Epoch 10/100\n",
      "145/145 [==============================] - 6s 42ms/step - loss: 2.0290 - accuracy: 0.1811 - val_loss: 2.0410 - val_accuracy: 0.1692\n",
      "Epoch 11/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0237 - accuracy: 0.1904 - val_loss: 2.0341 - val_accuracy: 0.1782\n",
      "Epoch 12/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0200 - accuracy: 0.1975 - val_loss: 2.0361 - val_accuracy: 0.1826\n",
      "Epoch 13/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0167 - accuracy: 0.1941 - val_loss: 2.0305 - val_accuracy: 0.1759\n",
      "Epoch 14/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0123 - accuracy: 0.1993 - val_loss: 2.0253 - val_accuracy: 0.1787\n",
      "Epoch 15/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0086 - accuracy: 0.2008 - val_loss: 2.0243 - val_accuracy: 0.1894\n",
      "Epoch 16/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0057 - accuracy: 0.2057 - val_loss: 2.0171 - val_accuracy: 0.1815\n",
      "Epoch 17/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.9983 - accuracy: 0.2075 - val_loss: 2.0211 - val_accuracy: 0.1754\n",
      "Epoch 18/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.9934 - accuracy: 0.2118 - val_loss: 2.0345 - val_accuracy: 0.1849\n",
      "Epoch 19/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.9886 - accuracy: 0.2174 - val_loss: 2.0245 - val_accuracy: 0.1944\n",
      "Epoch 20/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.9778 - accuracy: 0.2133 - val_loss: 2.0115 - val_accuracy: 0.1994\n",
      "Epoch 21/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.9847 - accuracy: 0.2185 - val_loss: 2.0161 - val_accuracy: 0.1787\n",
      "Epoch 22/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.9701 - accuracy: 0.2278 - val_loss: 2.0122 - val_accuracy: 0.1972\n",
      "Epoch 23/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.9635 - accuracy: 0.2258 - val_loss: 2.0051 - val_accuracy: 0.2050\n",
      "Epoch 24/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.9534 - accuracy: 0.2233 - val_loss: 2.0095 - val_accuracy: 0.1983\n",
      "Epoch 25/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.9516 - accuracy: 0.2349 - val_loss: 2.0075 - val_accuracy: 0.1961\n",
      "Epoch 26/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 2.0459 - accuracy: 0.1671 - val_loss: 2.0907 - val_accuracy: 0.1132\n",
      "Epoch 27/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 2.0866 - accuracy: 0.1338 - val_loss: 2.0832 - val_accuracy: 0.1361\n",
      "Epoch 28/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 2.0855 - accuracy: 0.1247 - val_loss: 2.0842 - val_accuracy: 0.1255\n",
      "Epoch 29/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0829 - accuracy: 0.1295 - val_loss: 2.0849 - val_accuracy: 0.1081\n",
      "Epoch 30/100\n",
      "145/145 [==============================] - 6s 41ms/step - loss: 2.0830 - accuracy: 0.1282 - val_loss: 2.0850 - val_accuracy: 0.1322\n",
      "Epoch 31/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 2.0820 - accuracy: 0.1325 - val_loss: 2.0847 - val_accuracy: 0.1429\n",
      "Epoch 32/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 2.0765 - accuracy: 0.1329 - val_loss: 2.0788 - val_accuracy: 0.1569\n",
      "Epoch 33/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 2.0692 - accuracy: 0.1502 - val_loss: 2.0703 - val_accuracy: 0.1552\n",
      "Epoch 34/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 2.0623 - accuracy: 0.1638 - val_loss: 2.0665 - val_accuracy: 0.1658\n",
      "Epoch 35/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 2.0555 - accuracy: 0.1651 - val_loss: 2.0563 - val_accuracy: 0.1647\n",
      "Epoch 36/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 2.0442 - accuracy: 0.1746 - val_loss: 2.0543 - val_accuracy: 0.1675\n",
      "Epoch 37/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 2.0477 - accuracy: 0.1755 - val_loss: 2.0438 - val_accuracy: 0.1793\n",
      "Epoch 38/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 2.0407 - accuracy: 0.1798 - val_loss: 2.0694 - val_accuracy: 0.1462\n",
      "Epoch 39/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 2.0585 - accuracy: 0.1632 - val_loss: 2.0614 - val_accuracy: 0.1501\n",
      "Epoch 40/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 2.0442 - accuracy: 0.1692 - val_loss: 2.0503 - val_accuracy: 0.1692\n",
      "Epoch 41/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 2.0194 - accuracy: 0.1878 - val_loss: 2.0578 - val_accuracy: 0.1625\n",
      "Epoch 42/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 2.0220 - accuracy: 0.1928 - val_loss: 2.0421 - val_accuracy: 0.1871\n",
      "Epoch 43/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 2.0128 - accuracy: 0.2060 - val_loss: 2.0203 - val_accuracy: 0.2022\n",
      "Epoch 44/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.9856 - accuracy: 0.2213 - val_loss: 1.9920 - val_accuracy: 0.1989\n",
      "Epoch 45/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.9639 - accuracy: 0.2308 - val_loss: 1.9988 - val_accuracy: 0.2034\n",
      "Epoch 46/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.9512 - accuracy: 0.2373 - val_loss: 1.9780 - val_accuracy: 0.2174\n",
      "Epoch 47/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.9336 - accuracy: 0.2470 - val_loss: 1.9586 - val_accuracy: 0.2235\n",
      "Epoch 48/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.9162 - accuracy: 0.2630 - val_loss: 1.9531 - val_accuracy: 0.2218\n",
      "Epoch 49/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.9072 - accuracy: 0.2544 - val_loss: 1.9478 - val_accuracy: 0.2387\n",
      "Epoch 50/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.8944 - accuracy: 0.2689 - val_loss: 1.9674 - val_accuracy: 0.2308\n",
      "Epoch 51/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.8945 - accuracy: 0.2637 - val_loss: 1.9480 - val_accuracy: 0.2297\n",
      "Epoch 52/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.8763 - accuracy: 0.2725 - val_loss: 1.9359 - val_accuracy: 0.2263\n",
      "Epoch 53/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.8647 - accuracy: 0.2833 - val_loss: 1.9365 - val_accuracy: 0.2431\n",
      "Epoch 54/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.8519 - accuracy: 0.2846 - val_loss: 1.9169 - val_accuracy: 0.2403\n",
      "Epoch 55/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.8362 - accuracy: 0.2877 - val_loss: 1.9238 - val_accuracy: 0.2459\n",
      "Epoch 56/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.8255 - accuracy: 0.2905 - val_loss: 1.9276 - val_accuracy: 0.2342\n",
      "Epoch 57/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.8157 - accuracy: 0.2920 - val_loss: 1.9165 - val_accuracy: 0.2431\n",
      "Epoch 58/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.7989 - accuracy: 0.2995 - val_loss: 1.9416 - val_accuracy: 0.2465\n",
      "Epoch 59/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.7864 - accuracy: 0.3043 - val_loss: 1.9108 - val_accuracy: 0.2476\n",
      "Epoch 60/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.7735 - accuracy: 0.3121 - val_loss: 1.9646 - val_accuracy: 0.2336\n",
      "Epoch 61/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.7917 - accuracy: 0.3082 - val_loss: 1.9286 - val_accuracy: 0.2476\n",
      "Epoch 62/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.7528 - accuracy: 0.3112 - val_loss: 1.9216 - val_accuracy: 0.2633\n",
      "Epoch 63/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.7361 - accuracy: 0.3287 - val_loss: 1.9213 - val_accuracy: 0.2566\n",
      "Epoch 64/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.7129 - accuracy: 0.3328 - val_loss: 1.9267 - val_accuracy: 0.2560\n",
      "Epoch 65/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.7028 - accuracy: 0.3439 - val_loss: 1.9327 - val_accuracy: 0.2527\n",
      "Epoch 66/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.6849 - accuracy: 0.3469 - val_loss: 1.9154 - val_accuracy: 0.2678\n",
      "Epoch 67/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.6705 - accuracy: 0.3540 - val_loss: 1.9198 - val_accuracy: 0.2700\n",
      "Epoch 68/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.6520 - accuracy: 0.3657 - val_loss: 1.9218 - val_accuracy: 0.2655\n",
      "Epoch 69/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.6352 - accuracy: 0.3713 - val_loss: 1.9225 - val_accuracy: 0.2678\n",
      "Epoch 70/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.6198 - accuracy: 0.3758 - val_loss: 1.9338 - val_accuracy: 0.2790\n",
      "Epoch 71/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.5920 - accuracy: 0.3860 - val_loss: 1.9675 - val_accuracy: 0.2723\n",
      "Epoch 72/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.5864 - accuracy: 0.3897 - val_loss: 1.9581 - val_accuracy: 0.2695\n",
      "Epoch 73/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.5562 - accuracy: 0.4022 - val_loss: 1.9376 - val_accuracy: 0.2700\n",
      "Epoch 74/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.5388 - accuracy: 0.4121 - val_loss: 1.9639 - val_accuracy: 0.2790\n",
      "Epoch 75/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.5200 - accuracy: 0.4165 - val_loss: 1.9489 - val_accuracy: 0.2796\n",
      "Epoch 76/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.4914 - accuracy: 0.4227 - val_loss: 1.9558 - val_accuracy: 0.2756\n",
      "Epoch 77/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.4910 - accuracy: 0.4348 - val_loss: 1.9491 - val_accuracy: 0.2941\n",
      "Epoch 78/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.4724 - accuracy: 0.4301 - val_loss: 1.9688 - val_accuracy: 0.2947\n",
      "Epoch 79/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.4499 - accuracy: 0.4472 - val_loss: 1.9871 - val_accuracy: 0.2829\n",
      "Epoch 80/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.4391 - accuracy: 0.4508 - val_loss: 1.9813 - val_accuracy: 0.2829\n",
      "Epoch 81/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.4093 - accuracy: 0.4625 - val_loss: 1.9981 - val_accuracy: 0.2908\n",
      "Epoch 82/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.4131 - accuracy: 0.4655 - val_loss: 2.0108 - val_accuracy: 0.2880\n",
      "Epoch 83/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.3708 - accuracy: 0.4837 - val_loss: 2.0438 - val_accuracy: 0.2913\n",
      "Epoch 84/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.3534 - accuracy: 0.4861 - val_loss: 2.0120 - val_accuracy: 0.2986\n",
      "Epoch 85/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.3514 - accuracy: 0.4865 - val_loss: 2.0486 - val_accuracy: 0.2947\n",
      "Epoch 86/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.3229 - accuracy: 0.5064 - val_loss: 2.0579 - val_accuracy: 0.2829\n",
      "Epoch 87/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.3052 - accuracy: 0.5077 - val_loss: 2.0409 - val_accuracy: 0.3003\n",
      "Epoch 88/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.2758 - accuracy: 0.5250 - val_loss: 2.0715 - val_accuracy: 0.2936\n",
      "Epoch 89/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.2712 - accuracy: 0.5202 - val_loss: 2.0520 - val_accuracy: 0.2913\n",
      "Epoch 90/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.2697 - accuracy: 0.5217 - val_loss: 2.0864 - val_accuracy: 0.2952\n",
      "Epoch 91/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.2565 - accuracy: 0.5243 - val_loss: 2.1161 - val_accuracy: 0.2975\n",
      "Epoch 92/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.2389 - accuracy: 0.5394 - val_loss: 2.0592 - val_accuracy: 0.3081\n",
      "Epoch 93/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.2051 - accuracy: 0.5602 - val_loss: 2.1006 - val_accuracy: 0.2857\n",
      "Epoch 94/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.1913 - accuracy: 0.5598 - val_loss: 2.1222 - val_accuracy: 0.3076\n",
      "Epoch 95/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.1806 - accuracy: 0.5686 - val_loss: 2.1758 - val_accuracy: 0.2969\n",
      "Epoch 96/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.1525 - accuracy: 0.5742 - val_loss: 2.1776 - val_accuracy: 0.2980\n",
      "Epoch 97/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.1341 - accuracy: 0.5799 - val_loss: 2.1916 - val_accuracy: 0.2980\n",
      "Epoch 98/100\n",
      "145/145 [==============================] - 6s 39ms/step - loss: 1.1184 - accuracy: 0.5898 - val_loss: 2.2076 - val_accuracy: 0.3081\n",
      "Epoch 99/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.1253 - accuracy: 0.5846 - val_loss: 2.1732 - val_accuracy: 0.3031\n",
      "Epoch 100/100\n",
      "145/145 [==============================] - 6s 40ms/step - loss: 1.1048 - accuracy: 0.5965 - val_loss: 2.1852 - val_accuracy: 0.3036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f78047f0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "# Add LSTM layer with 128 units and input shape of (190, 1)\n",
    "model2.add(LSTM(units=192, input_shape=(186, 1), return_sequences=True))\n",
    "\n",
    "# Add Dropout layer to reduce overfitting\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "# Add another LSTM layer with 64 units\n",
    "model2.add(LSTM(units=96, return_sequences=True))\n",
    "\n",
    "# Add Dropout layer\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "# Add a final LSTM layer with 32 units\n",
    "model2.add(LSTM(units=48))\n",
    "\n",
    "# Add Dropout layer\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "# Add Dense layer with 8 output classes and softmax activation\n",
    "model2.add(Dense(units=8, activation='softmax', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# fit network\n",
    "model2.fit(X_train, y_train, epochs=100,validation_data=(X_val,y_val), verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
